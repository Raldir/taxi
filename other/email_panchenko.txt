
Dear Mr. Panchenko,

sorry for writing in German. This semester we are working on the Shared Task <> for a NatS-Project.

Our goal is to understand, evaluate and hopefully extend the system which you and your 
colleagues implemented.

As a first step we tried to map the TAXI implementation to your paper for better understanding. The
folder "resources" consists of the crawled corpora as described in section 3.1. Therefore the vocabulary
of each domain (e.g. "science_en.csv") is being used to create more domain-specific resources. It consists
of many different paires and their frequency, so it can be used for the feature described in 3.3 (pattern).
Is this the main reason for crawling this huge amount of data - soley for the Hypernyms via patterns since
the substring method does not seem to rely on data outside the test data.
The pruning method uses the two features for each pair of words in the vocabulary provided by the test data
to calculate a ranking of hypernym-hyponym relation. As described in your paper, a SVM currenty yields the
best results. Would you say that it is reasonable to use for example a Neural Network, possibly on the
other features you explored as well, or did you already try it out?  

 All further
steps are applied on the common corpora combined with the domain-specific one that is created by given 
input files of the task.


3.5. Circle? Wo wird das im Code ausgef√ºhrt?



 
