{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import os\n",
    "\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from chinese_whispers import chinese_whispers, aggregate_clusters\n",
    "from gensim.models.poincare import PoincareModel\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the Networkx graph\n",
    "From a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_taxonomy(graph):\n",
    "    \"\"\" Display the taxonomy in a hierarchical layout \"\"\"\n",
    "    pos = graphviz_layout(graph, prog='dot', args=\"-Grankdir=LR\")\n",
    "    plt.figure(3,figsize=(48,144))\n",
    "    nx.draw(graph, pos, with_labels=True, arrows=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the networkx graph\n",
    "def process_input(taxonomy):\n",
    "    \"\"\" Read the taxonomy and generate a networkx graph \"\"\"\n",
    "\n",
    "    # Generated\n",
    "    df = pd.read_csv(\n",
    "        taxonomy,\n",
    "        sep='\\t',\n",
    "        header=None,\n",
    "        names=['hyponym', 'hypernym'],\n",
    "        usecols=[1,2],\n",
    "    )\n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    for rel in zip(list(df['hypernym']), list(df['hyponym'])):\n",
    "        rel_0 = rel[0]\n",
    "        rel_1 = rel[1]\n",
    "        # Simplify the compound words by replacing the whitespaces with underscores\n",
    "        if ' ' in rel[0]:\n",
    "            rel_0 = '_'.join(rel[0].split())\n",
    "        if ' ' in rel[1]:\n",
    "            rel_1 = '_'.join(rel[1].split())\n",
    "        G.add_edge(rel_0, rel_1)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxo_path = 'taxi_output/simple_full/science/science_en.csv-relations.csv-taxo-knn1.csv'\n",
    "gs_path = 'eval/taxi_eval_archive/gold_standard/science.taxo'\n",
    "\n",
    "G_taxo = process_input(taxo_path)\n",
    "G_gold = process_input(gs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes in GS: 452\n",
      "Nodes in G Taxo: 307\n"
     ]
    }
   ],
   "source": [
    "print('Nodes in GS:', len(set(G_gold.nodes())))\n",
    "print('Nodes in G Taxo:', len(set(G_taxo.nodes())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_nodes = set(G_gold.nodes()) - set(G_taxo.nodes())\n",
    "len(new_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors():\n",
    "    \"\"\" Load word vectors. \"\"\"\n",
    "\n",
    "    embedding_dir = '/home/5aly/taxi/distributed_semantics/embeddings/'\n",
    "\n",
    "    poincare_model = model = PoincareModel.load(embedding_dir + 'embeddings_poincare_wordnet')  # parent-cluster relationship\n",
    "    own_model = gensim.models.KeyedVectors.load(embedding_dir + 'own_embeddings_w2v')  # family-cluster relationship\n",
    "\n",
    "    return poincare_model, own_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "poincare_w2v, own_w2v = load_vectors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Taxonomy with Distributional Semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a networkx graph for each node containing only its children. Draw edges among the children based on the similarity with one another using word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_children_clusters(own_model, graph):\n",
    "    \"\"\" This function returns a dictionary where corresponding to each key(node) is a graph of its children \"\"\"\n",
    "    \n",
    "    clustered_graph = {}\n",
    "    for node in graph.nodes():\n",
    "        clustered_graph[node] = nx.Graph()\n",
    "        successors = [s.lower() for s in graph.successors(node)]\n",
    "\n",
    "        for successor in successors:\n",
    "            try:\n",
    "                for word, _ in own_model.most_similar(successor, topn=100):\n",
    "                    if word.lower() in successors:\n",
    "                        clustered_graph[node].add_edge(successor, word.lower())\n",
    "            except KeyError:  # If the word in not in vocabulary, check using the substring based method\n",
    "                successor_terms = successor.split('_')\n",
    "                if node in successor_terms:\n",
    "                    clustered_graph[node].add_node(successor)\n",
    "    \n",
    "    return clustered_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acharya/anaconda3/envs/tax3/lib/python3.6/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/acharya/anaconda3/envs/tax3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "GC = create_children_clusters(own_w2v, G_taxo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posI = graphviz_layout(GC['engineering'])\n",
    "# plt.figure(2, figsize=(20, 20))\n",
    "nx.draw(GC['engineering'], posI, with_labels=True, arrows=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Chinese Whispers Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new nodes\n",
    "- Loop through all the new nodes.\n",
    "- For each removed node, find out the family and parent in the graph that has the maximum similarity with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_improved = G_taxo.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(poincare_model, own_model, parent, family, node, exclude_parent, exclude_family):\n",
    "    \n",
    "    # Similarity between the parent and a cluster\n",
    "    parent_similarity = 0\n",
    "    if not exclude_parent:\n",
    "        node_senses = [n_sense.name() for n_sense in wn.synsets(node) if node in n_sense.name()]\n",
    "        parent_senses = [p_sense.name() for p_sense in wn.synsets(parent) if parent in p_sense.name()]\n",
    "        for parent_sense in parent_senses:\n",
    "            for node_sense in node_senses:\n",
    "                try:\n",
    "                    similarity = poincare_model.kv.similarity(parent_sense, node_sense)\n",
    "                    if similarity > parent_similarity:\n",
    "                        parent_similarity = similarity\n",
    "                except KeyError as e:\n",
    "                    if parent_sense in str(e):\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "    \n",
    "    # Similarity between a family and a cluster\n",
    "    family_similarity = 0\n",
    "    if not exclude_family:\n",
    "        family_similarities = []\n",
    "        for f_item in family:\n",
    "            try:\n",
    "                family_similarities.append(own_model.similarity(f_item, node))\n",
    "            except KeyError as e:  # skip the terms not in vocabulary\n",
    "                if node in str(e):\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "        if len(family_similarities) > 0:\n",
    "            family_similarity = sum(family_similarities) / len(family_similarities)\n",
    "    \n",
    "    # Final score is the average of both the similarities\n",
    "    return (parent_similarity + family_similarity) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acharya/anaconda3/envs/tax3/lib/python3.6/site-packages/ipykernel_launcher.py:26: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "/home/acharya/anaconda3/envs/tax3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "for node in new_nodes:\n",
    "    max_score = 0\n",
    "    max_score_node = ''\n",
    "    for p_node, graph in GC.items():\n",
    "        gc = chinese_whispers(graph, weighting='top', iterations=60)\n",
    "        for label, family in aggregate_clusters(gc).items():\n",
    "            score = calculate_similarity(poincare_w2v, own_w2v, p_node, family, node, False, False)\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                max_score_node = p_node\n",
    "    G_improved.add_edge(max_score_node, node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the nodes and the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_result(g_improved):\n",
    "    \"\"\" Filter the results i.e. remove all the isolated nodes and nodes with blank labels \"\"\"\n",
    "\n",
    "    print('\\nTuning the result...')\n",
    "\n",
    "    if '' in g_improved.nodes():\n",
    "        g_improved.remove_node('')\n",
    "\n",
    "    hypernyms = {x[0] for x in g_improved.edges()}\n",
    "    isolated_nodes = list(nx.isolates(g_improved))\n",
    "    for isolated_node in isolated_nodes:\n",
    "        terms = isolated_node.split('_')\n",
    "        if terms[-1] in hypernyms:\n",
    "            g_improved.add_edge(terms[-1], isolated_node)\n",
    "        elif terms[0] in hypernyms:\n",
    "            g_improved.add_edge(terms[0], isolated_node)\n",
    "        else:\n",
    "            g_improved.remove_node(isolated_node)\n",
    "\n",
    "    return g_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning the result...\n",
      "Tuned.\n"
     ]
    }
   ],
   "source": [
    "tune_result(G_improved)\n",
    "print('Tuned.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(result, path):\n",
    "    print('\\nSaving the result...')\n",
    "    df_improved = pd.DataFrame(list(result.edges()), columns=['hypernym', 'hyponym'])\n",
    "    df_improved = df_improved[df_improved.columns.tolist()[::-1]]\n",
    "\n",
    "    # Replace the underscores with blanks\n",
    "    df_improved['hyponym'] = df_improved['hyponym'].apply(lambda x: x.replace('_', ' '))\n",
    "    df_improved['hypernym'] = df_improved['hypernym'].apply(lambda x: x.replace('_', ' '))\n",
    "\n",
    "    # Store the result\n",
    "    output_path = os.path.join(\n",
    "        'taxi_output', 'distributional_semantics',\n",
    "        os.path.basename(path) + '-' + 'new_ds' + os.path.splitext(path)[-1]\n",
    "    )\n",
    "    df_improved.to_csv(output_path, sep='\\t', header=False)\n",
    "    print('Output saved at:', output_path)\n",
    "\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = save_result(G_improved, taxo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters(graph):\n",
    "    \"\"\" Clusterize the nodes of a particular domain in a given graph \"\"\"\n",
    "    graph_cluster = chinese_whispers(graph, weighting='top', iterations=60)\n",
    "    \n",
    "    # Visualize the clustering of graph_cluster using NetworkX (requires matplotlib)\n",
    "    colors = [1. / graph_cluster.node[node]['label'] for node in graph_cluster.nodes()]\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(20, 20)\n",
    "    nx.draw_networkx(graph_cluster, cmap=plt.get_cmap('jet'), node_color=colors, font_color='black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_improved = create_children_clusters(own_w2v, G_improved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = 'mechanical_engineering'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original clusters\n",
    "visualize_clusters(GC[domain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clusters after detaching\n",
    "visualize_clusters(GC_detached[domain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clusters after detaching and re-attaching the clusters\n",
    "visualize_clusters(GC_improved[domain])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the original taxonomy\n",
    "display_taxonomy(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the modified taxonomy\n",
    "display_taxonomy(G_improved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(G.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(G_improved.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
